{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9GLPRh/lsuTvL20fz1Nlp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ponaalagar/NLP/blob/main/prac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihh4kRedJtBr",
        "outputId": "2e5c80c1-8447-4e1c-c16f-7d0023684bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Tokens: ['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of']\n",
            "POS Tags: [('The', 'DT'), ('Fulton', 'NNP'), ('County', 'NNP'), ('Grand', 'NNP'), ('Jury', 'NNP'), ('said', 'VBD'), ('Friday', 'NNP'), ('an', 'DT'), ('investigation', 'NN'), ('of', 'IN')]\n",
            "Most Common Words: [('the', 5580), (',', 5188), ('.', 4180), ('of', 2849), ('and', 2146), ('to', 2116), ('a', 1993), ('in', 1893), ('``', 1434), ('for', 943)]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from nltk import pos_tag, word_tokenize, FreqDist\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# Load corpus and tokenize\n",
        "text = ' '.join(brown.words(categories='news'))\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# POS tagging\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "# Frequency distribution\n",
        "fdist = FreqDist(tokens)\n",
        "\n",
        "print(\"Sample Tokens:\", tokens[:10])\n",
        "print(\"POS Tags:\", pos_tags[:10])\n",
        "print(\"Most Common Words:\", fdist.most_common(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "\n",
        "words = [\"bank\", \"interest\", \"market\"]\n",
        "for word in words:\n",
        "    print(f\"\\nWord: {word}\")\n",
        "    synsets = wn.synsets(word)\n",
        "    for s in synsets[:3]:\n",
        "        print(\"Definition:\", s.definition())\n",
        "        print(\"Examples:\", s.examples())\n",
        "        print(\"Synonyms:\", [lemma.name() for lemma in s.lemmas()])\n",
        "        antonyms = [l.antonyms()[0].name() for l in s.lemmas() if l.antonyms()]\n",
        "        if antonyms:\n",
        "            print(\"Antonyms:\", antonyms)\n",
        "    print()\n",
        "\n",
        "tags = pos_tag(words)\n",
        "print(\"POS Tags:\", tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x1XgiwSK4hs",
        "outputId": "f32a0070-3fb1-40c1-913f-7f7a0766e002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word: bank\n",
            "Definition: sloping land (especially the slope beside a body of water)\n",
            "Examples: ['they pulled the canoe up on the bank', 'he sat on the bank of the river and watched the currents']\n",
            "Synonyms: ['bank']\n",
            "Definition: a financial institution that accepts deposits and channels the money into lending activities\n",
            "Examples: ['he cashed a check at the bank', 'that bank holds the mortgage on my home']\n",
            "Synonyms: ['depository_financial_institution', 'bank', 'banking_concern', 'banking_company']\n",
            "Definition: a long ridge or pile\n",
            "Examples: ['a huge bank of earth']\n",
            "Synonyms: ['bank']\n",
            "\n",
            "\n",
            "Word: interest\n",
            "Definition: a sense of concern with and curiosity about someone or something\n",
            "Examples: ['an interest in music']\n",
            "Synonyms: ['interest', 'involvement']\n",
            "Definition: a reason for wanting something done\n",
            "Examples: ['for your sake', 'died for the sake of his country', 'in the interest of safety', 'in the common interest']\n",
            "Synonyms: ['sake', 'interest']\n",
            "Definition: the power of attracting or holding one's attention (because it is unusual or exciting etc.)\n",
            "Examples: ['they said nothing of great interest', 'primary colors can add interest to a room']\n",
            "Synonyms: ['interest', 'interestingness']\n",
            "Antonyms: ['uninterestingness']\n",
            "\n",
            "\n",
            "Word: market\n",
            "Definition: the world of commercial activity where goods and services are bought and sold\n",
            "Examples: ['without competition there would be no market', 'they were driven from the marketplace']\n",
            "Synonyms: ['market', 'marketplace', 'market_place']\n",
            "Definition: the customers for a particular product or service\n",
            "Examples: ['before they publish any book they try to determine the size of the market for it']\n",
            "Synonyms: ['market']\n",
            "Definition: a marketplace where groceries are sold\n",
            "Examples: ['the grocery store included a meat market']\n",
            "Synonyms: ['grocery_store', 'grocery', 'food_market', 'market']\n",
            "\n",
            "POS Tags: [('bank', 'NN'), ('interest', 'NN'), ('market', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = \"NLP makes computers understand human language effectively.\"\n",
        "blob = TextBlob(text)\n",
        "\n",
        "print(\"Noun Phrases:\", blob.noun_phrases)\n",
        "print(\"Sentiment:\", blob.sentiment)\n",
        "print(\"Words:\", blob.words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzQTWjG2MBA4",
        "outputId": "99dbbcd0-ffe2-49ee-feda-87b3eba992d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun Phrases: ['nlp', 'human language']\n",
            "Sentiment: Sentiment(polarity=0.3, subjectivity=0.45)\n",
            "Words: ['NLP', 'makes', 'computers', 'understand', 'human', 'language', 'effectively']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVXAyTJeMe-Y",
        "outputId": "9a75882a-b922-41db-f1fd-cc7bb1e5f8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "text = \"I can't believe it's already running faster!\"\n",
        "expanded = contractions.fix(text)\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = expanded.split()\n",
        "stems = [stemmer.stem(w) for w in words]\n",
        "lemmas = [lemmatizer.lemmatize(w) for w in words]\n",
        "\n",
        "print(\"Expanded:\", expanded)\n",
        "print(\"Stems:\", stems)\n",
        "print(\"Lemmas:\", lemmas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZAFe5C5MdYp",
        "outputId": "774a3356-1c70-45e4-887f-8020a6743768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expanded: I cannot believe it is already running faster!\n",
            "Stems: ['i', 'cannot', 'believ', 'it', 'is', 'alreadi', 'run', 'faster!']\n",
            "Lemmas: ['I', 'cannot', 'believe', 'it', 'is', 'already', 'running', 'faster!']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_WXQFUJvUPzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "docs = [\"I love this product\", \"This is terrible\", \"Amazing experience\", \"Bad quality\"]\n",
        "labels = [\"pos\", \"neg\", \"pos\", \"neg\"]\n",
        "\n",
        "#vect = CountVectorizer()\n",
        "vect = TfidfVectorizer()\n",
        "x = vect.fit_transform(docs)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(x,labels)\n",
        "\n",
        "test = [\"I hate this\", \"I really love it\"]\n",
        "pred = model.predict(vect.transform(test))\n",
        "\n",
        "print(\"Predictions:\", pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iPzmBFBUPeI",
        "outputId": "bb0675ed-bd29-4983-adf6-0b4633f880eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: ['neg' 'pos']\n"
          ]
        }
      ]
    }
  ]
}